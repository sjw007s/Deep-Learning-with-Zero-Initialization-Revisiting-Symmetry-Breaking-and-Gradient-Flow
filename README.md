# Deep Learning with Zero Initialization: Revisiting Symmetry Breaking and Gradient Flow

Jongwoo Seo (1st author)  
Preprint: [Link](https://www.researchsquare.com/article/rs-4890533/v2)  
LinkedIn: [Link](https://www.linkedin.com/in/jongwoo-seo/)  
Personal Website: [Link](https://sites.google.com/view/jongwooseo/)  
CV: [Link](https://sites.google.com/view/jongwooseo/cv?authuser=0)  
Google Scholar: [Link](https://scholar.google.co.kr/citations?hl=en&user=ikhaAuoAAAAJ)  
Contact: sjw007s@korea.ac.kr  

ðŸ“¢ðŸ“¢ðŸ“¢  
1. Seeking PhD positions and industry opportunities â€” email me.  
ðŸš©  
2. Understanding the information flow between operations during forward and backward propagation is not exclusive knowledgeâ€”itâ€™s something anyone can learn. Still, some researchers may not be familiar with it. I'm open to contributingâ€”whether itâ€™s support, collaboration, or consultingâ€”especially when proper credit is given (e.g., co-authorship, employment opportunity, or other fair recognition). If you're interested, feel free to reach out.  
ðŸ“¢ðŸ“¢ðŸ“¢  

---

### 1. The four files below provide dataloader code for each dataset.

- `CNN_CIFAR_100_github.ipynb`  
- `CNN_CIFAR_10_github.ipynb`  
- `CNN_Mnist_github.ipynb`
- `tiny_imagenet.py`

---

### 2. The three files below provide code for each model.  
You can reproduce results by combining the previously mentioned dataloaders with each model.

- `cifar-10-Mixer_github.py`  
- `cifar-10-ViT_github.py`  
- `cifar-10-resnet_github.py`

---

### 3. All you need to edit is just 2 lines:

```python
torch.nn.init.zeros_(a.weight) #"a" may vary depending on the code.
torch.nn.init.zeros_(a.bias) #"a" may vary depending on the code.
```
---

### 4. Functions like train() and test() may differ slightly depending on data preprocessing methods and models.

### 5. This file contains MLP-Mixer models on the Tiny ImageNet dataset, with all weights and biases initialized to zero, except for LayerNorm parameters initialized to one. There are no randomly initialized parameters at all.
- `tiny_imagenet_allconstant.py`  
