{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66d91ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import csv\n",
    "import os\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "from torch import Tensor\n",
    "from typing import Callable, List, Optional, Type, Union\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch import nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97493bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [] \n",
    "train_labels = [] \n",
    "class_to_idx = {}\n",
    "\n",
    "transform_before = transforms_v2.Compose([\n",
    "                            transforms_v2.ToImage(),\n",
    "                            transforms_v2.ToDtype(dtype = torch.float32, scale=True),\n",
    "                            transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                        ])\n",
    "\n",
    "transform_train = transforms_v2.Compose([\n",
    "                            transforms_v2.RandomResizedCrop(64, scale=(0.6, 1.0), ratio=(0.8, 1.2)),\n",
    "                            transforms_v2.RandomHorizontalFlip(p=0.5),\n",
    "                            transforms_v2.ColorJitter(\n",
    "                                brightness=0.4,\n",
    "                                contrast=0.4,\n",
    "                                saturation=0.4,\n",
    "                                hue=0.1\n",
    "                            ),\n",
    "                            transforms_v2.RandomAffine(\n",
    "                                degrees=15,\n",
    "                                translate=(0.1, 0.1),\n",
    "                            ),\n",
    "                            transforms_v2.RandomGrayscale(p=0.1)\n",
    "                        ])\n",
    "\n",
    "class_folders = os.listdir(r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\tiny-imagenet-200\\train\")\n",
    "for num, i in enumerate(class_folders):\n",
    "    class_to_idx[i] = num\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    folder_path = os.path.join(r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\tiny-imagenet-200\\train\", class_folder) +r\"\\images\"\n",
    "    temp_image = []\n",
    "    temp_label = []\n",
    "    for img_file in os.listdir(folder_path): \n",
    "        img_path = os.path.join(folder_path, img_file) \n",
    "\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img_tensor = transform_before(img)  \n",
    "\n",
    "        train_images.append(img_tensor)\n",
    "        train_labels.append(torch.tensor(class_to_idx[class_folder],dtype=torch.long))\n",
    "\n",
    "train_images = torch.stack(train_images)\n",
    "train_labels = torch.stack(train_labels)\n",
    "########################################################################\n",
    "test_images = [] \n",
    "test_labels = [] \n",
    "\n",
    "with open(r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\tiny-imagenet-200\\val\\val_annotations.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        file, idx, _ = line.strip().split('\\t', 2) # Split each line by space into folder name and index\n",
    "        img_path = os.path.join(r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\tiny-imagenet-200\\val\\images\", file) \n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img_tensor = transform_before(img)  \n",
    "\n",
    "        test_images.append(img_tensor)\n",
    "        test_labels.append(torch.tensor(class_to_idx[idx],dtype=torch.long))\n",
    "\n",
    "test_images = torch.stack(test_images).to(\"cuda\")\n",
    "test_labels = torch.stack(test_labels).to(\"cuda\")\n",
    "\n",
    "training_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=500, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=500, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c983e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_planes,\n",
    "        out_planes,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
    "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
    "    # according to \"Deep residual learning for image recognition\" https://arxiv.org/abs/1512.03385.\n",
    "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
    "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
    "\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        #print(\"ã…Ž\")\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Bottleneck],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "      \n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                f\"or a 3-element tuple, got {replace_stride_with_dilation}\"\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        #torch.nn.init.zeros_(self.fc.weight)\n",
    "        \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \"\"\"\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        #print(x.shape)\n",
    "        x = self.layer1(x)\n",
    "        #print(x.shape)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        #print(x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, scaler, transform_train):   \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = transform_train(X).to(\"cuda\")\n",
    "        y = y.to(\"cuda\")\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "            pred = model(X)\n",
    "            batch_loss_result = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        scaler.scale(batch_loss_result).backward() # Backpropagation: compute gradients\n",
    "        scaler.step(optimizer) # Update model parameters using the optimizer\n",
    "        scaler.update() # Update the gradient scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866765ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model):\n",
    "    with torch.no_grad():\n",
    "        accuracy_sum=0\n",
    "        for _, (X, y) in enumerate(dataloader):\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
    "                pred = model(X)\n",
    "            accuracy_sum+= (torch.argmax(pred, dim=1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        print(\"test_accuracy\", accuracy_sum/10000)\n",
    "    return accuracy_sum/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72201cb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = list()\n",
    "total_list = []\n",
    "for i in range(1):\n",
    "    model = ResNet(Bottleneck,[3,4,6,3],num_classes=200).to(\"cuda\")\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.95)\n",
    "    accuracy = 0 \n",
    "    epoch_list = []\n",
    "    for t in range(500):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(training_dataloader, model, loss_fn, optimizer, scaler, transform_train)\n",
    "        accuracy_temp = test(test_dataloader, model)\n",
    "        epoch_list.append(accuracy_temp)\n",
    "        scheduler.step()\n",
    "        if accuracy_temp > accuracy:\n",
    "            accuracy = accuracy_temp\n",
    "    total_list.append(epoch_list)\n",
    "    summary.append(accuracy)\n",
    "    print(summary)\n",
    "with open(\"tiny_1.csv\", mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(total_list)\n",
    "print(\"Done!\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
