{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    loss_sum=0\n",
    "    \n",
    "    for X, y in dataloader:     \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        batch_loss_result = loss_fn(pred, y)\n",
    "        batch_loss_result.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum+=batch_loss_result.item()\n",
    "        \n",
    "    loss_sum=loss_sum/len(dataloader.dataset)\n",
    "    return loss_sum\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_sum = 0\n",
    "        top1_correct = 0\n",
    "        top5_correct = 0\n",
    "        total_samples = 50_000\n",
    "        batch_size = 50\n",
    "\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)  \n",
    "\n",
    "            batch_loss_result = loss_fn(pred, y)\n",
    "            loss_sum += batch_loss_result.item()\n",
    "\n",
    "            softmax_pred = torch.softmax(pred, dim=1)\n",
    "            view_softmax_pred = softmax_pred.view(batch_size, 10, 1000)\n",
    "            mean_view_softmax_pred = view_softmax_pred.mean(dim=1)\n",
    "            top1_pred = torch.argmax(mean_view_softmax_pred, dim=1)\n",
    "            \n",
    "            view_y = y.view(batch_size, 10, 1000)\n",
    "            mean_view_y = view_y.mean(dim=1)\n",
    "            top1_y = torch.argmax(mean_view_y, dim=1)\n",
    "\n",
    "            top1_correct += (top1_pred == top1_y).sum().item()\n",
    "\n",
    "            _, top5_pred = torch.topk(mean_view_softmax_pred, 5, dim=1)  \n",
    "            top1_y_expanded = top1_y.view(-1, 1)  \n",
    "            top5_correct += torch.sum(torch.eq(top5_pred, top1_y_expanded)).item()\n",
    "\n",
    "        avg_loss = loss_sum / (10*total_samples)\n",
    "        top1_accuracy = top1_correct / total_samples\n",
    "        top5_accuracy = top5_correct / total_samples\n",
    "\n",
    "    return avg_loss, top1_accuracy, top5_accuracy\n",
    "\n",
    "epochs = 1\n",
    "summary_top1 = list()\n",
    "summary_top5 = list()\n",
    "epoch_durations = list()\n",
    "train_losses = list()\n",
    "test_losses = list()\n",
    "\n",
    "for i in range(1):\n",
    "    model = model().to(\"cuda\") #if you want to apply new model, declare new object. Do not change the name \"model\"\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.95)\n",
    "    \n",
    "    top1_accuracy = 0\n",
    "    top5_accuracy = 0 \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_loss, top1_temp, top5_temp = test(test_dataloader, model, loss_fn)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_duration = time.time() - start_time\n",
    "\n",
    "        epoch_durations.append(epoch_duration)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        summary_top1.append(top1_temp)\n",
    "        summary_top5.append(top5_temp)\n",
    "\n",
    "        if top1_temp > top1_accuracy:\n",
    "            top1_accuracy = top1_temp\n",
    "\n",
    "        if top5_temp > top5_accuracy:\n",
    "            top5_accuracy = top5_temp\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
