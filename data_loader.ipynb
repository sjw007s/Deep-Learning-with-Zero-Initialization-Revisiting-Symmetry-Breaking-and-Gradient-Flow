{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "My computer system specification\n",
    "i9-10900X\n",
    "RAM 64GB\n",
    "Samsung SSD 970 PRO 512GB\n",
    "RTX 3090 2 units\n",
    "\n",
    "Window 11\n",
    "Pytorch 2.5.1\n",
    "Anaconda3-2024.10-1-Windows-x86_64\n",
    "cudnn-windows-x86_64-8.9.7.29_cuda12-archive\n",
    "cuda_12.4.0_windows_network\n",
    "\n",
    "Email: sjw007s@korea.ac.kr\n",
    "\"\"\"\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_file, decode_jpeg\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import Lock\n",
    "\n",
    "\n",
    "# GPU setting\n",
    "torch.cuda.set_device(0)\n",
    "print(\"GPU device currently in use:\", torch.cuda.current_device())\n",
    "\n",
    "# Parsing a mapping file (reading a text file) from 2017 ILSVRC kit for target label\n",
    "def train_parse_mapping_file(mapping_file):\n",
    "    class_to_idx = {}\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        for line in f:\n",
    "            folder, idx, _ = line.strip().split(' ', 2)\n",
    "            class_to_idx[folder] = int(idx)-1  \n",
    "    return class_to_idx\n",
    "\n",
    "# Parsing validation ground truth file\n",
    "def test_parse_mapping_file(mapping_file):\n",
    "    class_to_idx = []\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        for line in f:\n",
    "            number = line.strip()\n",
    "            class_to_idx.append(int(number)-1)\n",
    "    return class_to_idx\n",
    "\n",
    "# training data augmentation\n",
    "transform_train = transforms_v2.Compose([\n",
    "    transforms_v2.RandomResize(min_size=256, max_size=481),\n",
    "    transforms_v2.RandomHorizontalFlip(p=0.5),\n",
    "    transforms_v2.ToDtype(torch.float32, scale=True), \n",
    "    transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms_v2.RandomCrop((224, 224))\n",
    "])\n",
    "\n",
    "# test data augmentation\n",
    "transform_test = transforms_v2.Compose([\n",
    "    transforms_v2.Resize(256), \n",
    "    transforms_v2.CenterCrop(256),\n",
    "    transforms_v2.ToDtype(torch.float32, scale=True),   \n",
    "    transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms_v2.TenCrop(224)\n",
    "])\n",
    "\n",
    "# training dataset\n",
    "class ImageNetDataset_train(Dataset): \n",
    "    def __init__(self, root_dir, mapping_file, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.class_to_idx = train_parse_mapping_file(mapping_file)\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "        self.lock = Lock()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "            executor.map(self._scan_folder, os.listdir(root_dir))\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long, device='cuda')\n",
    "        self.labels = F.one_hot(self.labels, num_classes=1000).float()\n",
    "        print(\"training dataset load complete\")\n",
    "\n",
    "    def _scan_folder(self, class_folder):\n",
    "        folder_path = os.path.join(self.root_dir, class_folder)\n",
    "        \n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            \n",
    "            with self.lock:\n",
    "                self.img_paths.append(img_path)\n",
    "                self.labels.append(self.class_to_idx[class_folder])\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.img_paths) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img_bytes = read_file(img_path)\n",
    "        img_tensor = decode_jpeg(img_bytes, device='cuda')\n",
    "    \n",
    "        img_tensor = self.transform(img_tensor)\n",
    "        \n",
    "        return img_tensor, label\n",
    "\n",
    "# test dataset\n",
    "class ImageNetDataset_test(Dataset):\n",
    "    def __init__(self, root_dir, mapping_file, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.img_paths = []\n",
    "        self.labels = test_parse_mapping_file(mapping_file)\n",
    "        self._scan_folder()\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long, device='cuda')\n",
    "        self.labels = F.one_hot(self.labels, num_classes=1000).float()\n",
    "        print(\"test dataset load complete\")\n",
    "\n",
    "    def _scan_folder(self):\n",
    "        for img_file in sorted(os.listdir(self.root_dir)):\n",
    "            img_path = os.path.join(self.root_dir, img_file)\n",
    "            self.img_paths.append(img_path)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img_bytes = read_file(img_path)\n",
    "        img_tensor = decode_jpeg(img_bytes, device='cuda')\n",
    "        \n",
    "        img_tensor = self.transform(img_tensor)\n",
    "        \n",
    "        return img_tensor, label\n",
    "\n",
    "def test_collate(batch):\n",
    "    imgs, labels = zip(*batch)  \n",
    "    imgs = list(imgs)\n",
    "    for i in range(50):\n",
    "        imgs[i] = torch.stack(imgs[i])\n",
    "    imgs = torch.stack(imgs)\n",
    "    imgs = imgs.reshape(500, 3, 224, 224)\n",
    "    \n",
    "    labels = torch.stack(labels)\n",
    "    labels = torch.repeat_interleave(labels, 10, dim=0)\n",
    "    return imgs, labels\n",
    "\n",
    "train_dir = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\ILSVRC2012_img_train\"  # training data location\n",
    "train_mapping_file = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\map_clsloc.txt\"  # training data mapping file location\n",
    "trainset = ImageNetDataset_train(root_dir=train_dir, mapping_file=train_mapping_file, transform=transform_train) \n",
    "train_dataloader = DataLoader(trainset, batch_size=512, shuffle=True)\n",
    "################################################################\n",
    "test_dir = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\ILSVRC2012_img_val\"  # test data location\n",
    "test_mapping_file = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\ILSVRC2012_validation_ground_truth.txt\"  # test data target label location\n",
    "testset = ImageNetDataset_test(root_dir=test_dir, mapping_file = test_mapping_file, transform=transform_test)  \n",
    "test_dataloader = DataLoader(testset, batch_size=50, shuffle=False, collate_fn = test_collate) \n",
    "\n",
    "for i, (batch, target) in enumerate(train_dataloader):\n",
    "    print(i, batch.shape, target.shape)\n",
    "    break\n",
    "\n",
    "for i, (batch, target) in enumerate(test_dataloader):\n",
    "    print(i, batch.shape, target.shape)\n",
    "    break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
