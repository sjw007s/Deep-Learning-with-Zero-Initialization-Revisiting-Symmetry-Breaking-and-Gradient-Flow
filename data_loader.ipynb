{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "My computer system specification\n",
    "i9-10900X\n",
    "RAM 64GB\n",
    "Samsung SSD 970 PRO 512GB\n",
    "RTX 3090 2 units\n",
    "\n",
    "Window 11\n",
    "Pytorch 2.5.1\n",
    "Anaconda3-2024.10-1-Windows-x86_64\n",
    "cudnn-windows-x86_64-8.9.7.29_cuda12-archive\n",
    "cuda_12.4.0_windows_network\n",
    "\n",
    "Email: sjw007s@korea.ac.kr\n",
    "\"\"\"\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms.v2 as transforms_v2\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_file, decode_jpeg\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import Lock\n",
    "\n",
    "\n",
    "# GPU setting\n",
    "torch.cuda.set_device(0) # Set the GPU device to be used (device 0)\n",
    "print(\"GPU device currently in use:\", torch.cuda.current_device()) # Print the current GPU device\n",
    "\n",
    "# Parsing a mapping file (reading a text file) from 2017 ILSVRC kit for target label\n",
    "def train_parse_mapping_file(mapping_file):\n",
    "    class_to_idx = {} # Dictionary to store class-to-index mappings\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        for line in f:\n",
    "            folder, idx, _ = line.strip().split(' ', 2) # Split each line by space into folder name and index\n",
    "            class_to_idx[folder] = int(idx)-1   # Map the folder to its corresponding index (adjusted by -1 for zero-indexing)\n",
    "    return class_to_idx\n",
    "\n",
    "# Parsing validation ground truth file\n",
    "def test_parse_mapping_file(mapping_file):\n",
    "    class_to_idx = [] # List to store validation labels\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        for line in f:\n",
    "            number = line.strip() # Read each line and strip any extra whitespace\n",
    "            class_to_idx.append(int(number)-1) # Append the class index to the list (adjusted by -1)\n",
    "    return class_to_idx\n",
    "\n",
    "# training data augmentation\n",
    "transform_train = transforms_v2.Compose([\n",
    "    transforms_v2.RandomResize(min_size=256, max_size=481), # Randomly resize image between 256 and 481 pixels\n",
    "    transforms_v2.RandomHorizontalFlip(p=0.5), # 50% chance of horizontally flipping the image\n",
    "    transforms_v2.ToDtype(torch.float32, scale=True),  # Convert image to float32 and scale to [0, 1]\n",
    "    transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize with ImageNet mean and std\n",
    "    transforms_v2.RandomCrop(224) # Randomly crop to 224x224\n",
    "])\n",
    "\n",
    "# test data augmentation\n",
    "transform_test = transforms_v2.Compose([\n",
    "    transforms_v2.Resize(256),  # Resize the shorter side to 256 pixels\n",
    "    transforms_v2.CenterCrop(256), # Center crop the image to 256x256\n",
    "    transforms_v2.ToDtype(torch.float32, scale=True),   # Convert to float32 and scale\n",
    "    transforms_v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize\n",
    "    transforms_v2.TenCrop(224) # Apply ten-crop augmentation (corner and center crops)\n",
    "])\n",
    "\n",
    "# training dataset\n",
    "class ImageNetDataset_train(Dataset): \n",
    "    def __init__(self, root_dir, mapping_file, transform):\n",
    "        self.root_dir = root_dir # Directory containing training images\n",
    "        self.transform = transform # Transformations to apply to each image\n",
    "        self.class_to_idx = train_parse_mapping_file(mapping_file) # Parse mapping file for class indices\n",
    "        self.img_paths = [] # List to store image file paths\n",
    "        self.labels = [] # List to store labels\n",
    "        self.lock = Lock() # Lock to ensure thread safety during multithreading\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=40) as executor: # Use ThreadPoolExecutor to scan the folder concurrently\n",
    "            executor.map(self._scan_folder, os.listdir(root_dir))\n",
    "\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long) # Convert labels to tensor and apply one-hot encoding\n",
    "        self.labels = F.one_hot(self.labels, num_classes=1000).float()\n",
    "\n",
    "        print(\"training dataset load complete\") # Print completion message\n",
    "\n",
    "    def _scan_folder(self, class_folder): # Scan each folder for images and assign labels\n",
    "        folder_path = os.path.join(self.root_dir, class_folder) # Get full folder path\n",
    "        \n",
    "        for img_file in os.listdir(folder_path): # Iterate through images in the folder\n",
    "            img_path = os.path.join(folder_path, img_file) # Get full image path\n",
    "            \n",
    "            label = self.class_to_idx[class_folder] # Get label from class_to_idx mapping\n",
    "\n",
    "            with self.lock: # Ensure thread safety\n",
    "                self.img_paths.append(img_path) # Add image path to list\n",
    "                self.labels.append(label) # Add label to list\n",
    "\n",
    "    def __len__(self):  # Return the total number of images in the dataset\n",
    "        return len(self.img_paths) \n",
    "    \n",
    "    def __getitem__(self, idx): # Get image and label by index\n",
    "        img_path = self.img_paths[idx] # Get image path\n",
    "        label = self.labels[idx] # Get label\n",
    "\n",
    "        img_bytes = read_file(img_path) # Read image as bytes\n",
    "        img_tensor = decode_jpeg(img_bytes, device='cuda') # Decode JPEG and move to GPU\n",
    "    \n",
    "        img_tensor = self.transform(img_tensor) # Apply transformations to the image\n",
    "        \n",
    "        return img_tensor, label.to('cuda') # Return image and label (moved to GPU)\n",
    "\n",
    "# test dataset\n",
    "class ImageNetDataset_test(Dataset):\n",
    "    def __init__(self, root_dir, mapping_file, transform):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.img_paths = []\n",
    "        self.labels = test_parse_mapping_file(mapping_file)\n",
    "        self._scan_folder()\n",
    "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
    "        self.labels = F.one_hot(self.labels, num_classes=1000).float()\n",
    "        \n",
    "        print(\"test dataset load complete\")\n",
    "\n",
    "    def _scan_folder(self): \n",
    "        for img_file in sorted(os.listdir(self.root_dir)): # Scan images in sorted order\n",
    "            img_path = os.path.join(self.root_dir, img_file)\n",
    "            self.img_paths.append(img_path)\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img_bytes = read_file(img_path)\n",
    "        img_tensor = decode_jpeg(img_bytes, device='cuda')\n",
    "        \n",
    "        img_tensor = self.transform(img_tensor)\n",
    "        \n",
    "        return img_tensor, label.to('cuda')\n",
    "\n",
    "def test_collate(batch): # Custom collate function for batching test data\n",
    "    imgs, labels = zip(*batch)   # Unzip batch into images and labels\n",
    "    imgs = list(imgs) # Convert to list for stacking\n",
    "    for i in range(50):\n",
    "        imgs[i] = torch.stack(imgs[i]) # Stack ten-crop images\n",
    "    imgs = torch.stack(imgs) # Stack into final batch\n",
    "    imgs = imgs.reshape(500, 3, 224, 224) # Reshape to batch size 500\n",
    "    \n",
    "    labels = torch.stack(labels) # Stack labels\n",
    "    labels = torch.repeat_interleave(labels, 10, dim=0) # Repeat labels for ten-crop\n",
    "    return imgs, labels\n",
    "\n",
    "train_dir = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\ILSVRC2012_img_train\"  # training data location\n",
    "train_mapping_file = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\map_clsloc.txt\"  # training data mapping file location\n",
    "trainset = ImageNetDataset_train(root_dir=train_dir, mapping_file=train_mapping_file, transform=transform_train) \n",
    "train_dataloader = DataLoader(trainset, batch_size=512, shuffle=True)\n",
    "################################################################\n",
    "test_dir = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\ILSVRC2012_img_val\"  # test data location\n",
    "test_mapping_file = r\"C:\\Users\\sjw00\\OneDrive\\Desktop\\dataset\\imagenet\\ILSVRC2012_validation_ground_truth.txt\"  # test data target label location\n",
    "testset = ImageNetDataset_test(root_dir=test_dir, mapping_file = test_mapping_file, transform=transform_test)  \n",
    "test_dataloader = DataLoader(testset, batch_size=50, shuffle=False, collate_fn = test_collate) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
